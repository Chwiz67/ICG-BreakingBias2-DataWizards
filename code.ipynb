{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.layers import *\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
    "SEQUENCE_LENGTH = 16\n",
    "DATASET_DIR = '' # Change this to the path of the dataset\n",
    "CLASSES_LIST = ['Brawl', 'Peace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    frames_list = []\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
    "\n",
    "    for frame_counter in range(SEQUENCE_LENGTH):\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "        success, frame = video_reader.read()\n",
    "        if not success:\n",
    "            break\n",
    "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        normalized_frame = resized_frame / 255\n",
    "        frames_list.append(normalized_frame)\n",
    "\n",
    "    video_reader.release()\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(DATASET_DIR):\n",
    "    features = []\n",
    "    labels = []\n",
    "    video_files_paths = []\n",
    "\n",
    "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
    "        for file_name in files_list:\n",
    "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
    "            frames = frames_extraction(video_file_path)\n",
    "            if len(frames) == SEQUENCE_LENGTH:\n",
    "                features.append(frames)\n",
    "                labels.append(class_index)\n",
    "                video_files_paths.append(video_file_path)\n",
    "\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return features, labels, video_files_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, video_files_paths = create_dataset(DATASET_DIR=DATASET_DIR)\n",
    "one_hot_encoded_labels = to_categorical(labels)\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.2, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = MobileNetV2( include_top=False , weights=\"imagenet\")\n",
    "mobilenet.trainable=True\n",
    "for layer in mobilenet.layers[:-40]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape = (SEQUENCE_LENGTH, IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
    "    model.add(TimeDistributed(mobilenet))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    lstm_fw = LSTM(units=64)\n",
    "    lstm_bw = LSTM(units=64, go_backwards = True)\n",
    "    model.add(Bidirectional(lstm_fw, backward_layer = lstm_bw))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dense(16,activation='relu'))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(len(CLASSES_LIST), activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 10, restore_best_weights = True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=5, min_lr=0.0000005, verbose=1)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "MobBiLSTM_model_history = model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4, shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback,reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICT_DATASET_DIR = '' # Change this to the path of the predict dataset\n",
    "predict_features, predict_labels, predict_video_files_paths = create_dataset(DATASET_DIR=PREDICT_DATASET_DIR)\n",
    "predict_labels = to_categorical(predict_labels)\n",
    "\n",
    "pred = model.predict(predict_features)\n",
    "predicted_classes = np.argmax(pred, axis = 1)\n",
    "print(classification_report(np.argmax(predict_labels, axis = 1), predicted_classes, target_names = CLASSES_LIST))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
